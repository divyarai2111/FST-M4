Windows PowerShell
Copyright (C) Microsoft Corporation. All rights reserved.

Install the latest PowerShell for new features and improvements! https://aka.ms/PSWindows

PS C:\Users\00118Z744> docker exec -it containerName bash
Error: No such container: containerName
PS C:\Users\00118Z744> docker container run -it -p 9870:9870 -p 8088:8088 registry.gitlab.com/training-support/training-environments:hadoop-v1 bash
/
 * Starting OpenBSD Secure Shell server sshd                                                                     [ OK ]
Waiting for hdfs to exit from safemode
Safe mode is OFF
Started
root@039eda7161c0:/# vim EmpData.csv
root@039eda7161c0:/# hive
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/apache-hive-3.1.2-bin/lib/log4j-slf4j-impl-2.10.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop-3.3.1/share/hadoop/common/lib/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Hive Session ID = 3bad413c-6db5-410a-84f0-638e5931fc0d

Logging initialized using configuration in jar:file:/usr/local/apache-hive-3.1.2-bin/lib/hive-common-3.1.2.jar!/hive-log4j2.properties Async: true
Hive Session ID = cb367e12-0de9-4679-8d20-580652fdce70
Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
hive> show databases;
OK
default
Time taken: 1.431 seconds, Fetched: 1 row(s)
hive> create database office;
OK
Time taken: 0.164 seconds
hive>  use office;
OK
Time taken: 0.058 seconds
hive> CREATE TABLE employee
    > (id INT, name STRING, dept STRING, yoj INT, salary INT)
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
    > TBLPROPERTIES ("skip.header.line.count"="1");
OK
Time taken: 0.77 seconds
hive> DESCRIBE employee;
OK
id                      int
name                    string
dept                    string
yoj                     int
salary                  int
Time taken: 0.254 seconds, Fetched: 5 row(s)
hive> LOAD DATA LOCAL INPATH
    > '/EmpData.csv'
    > INTO TABLE employee;
Loading data to table office.employee
OK
Time taken: 1.208 seconds
hive> SELECT * FROM employee;
OK
1       Ian     Quality Assurance       2021    28113
2       Beatrice        Tech Support    2021    35330
3       Vladimir        Human Resources 2020    51445
4       Whitney IT      2020    23818
5       Leslie  Customer Service        2021    59882
6       Bernard IT      2021    50330
7       Mary    Customer Service        2021    26558
8       Jerome  RnD     2021    45333
9       Joshua  IT      2021    59538
10      Keane   Human Resources 2022    46500
11      Velma   Human Resources 2022    19816
12      Rogan   Tech Support    2022    27554
13      Aurelia RnD     2021    20762
14      Merrill Quality Assurance       2021    59660
15      Blaine  Tech Support    2022    28768
Time taken: 2.305 seconds, Fetched: 15 row(s)
hive> SELECT COUNT(*) FROM employee;
Query ID = root_20221228042900_9d9cab48-b10b-480d-ad36-a5b05be82c13
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1672201518957_0001, Tracking URL = http://039eda7161c0:8088/proxy/application_1672201518957_0001/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1672201518957_0001
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2022-12-28 04:29:16,294 Stage-1 map = 0%,  reduce = 0%
2022-12-28 04:29:21,604 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.18 sec
2022-12-28 04:29:28,948 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 6.92 sec
MapReduce Total cumulative CPU time: 6 seconds 920 msec
Ended Job = job_1672201518957_0001
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 6.92 sec   HDFS Read: 13143 HDFS Write: 102 SUCCESS
Total MapReduce CPU Time Spent: 6 seconds 920 msec
OK
15
Time taken: 31.099 seconds, Fetched: 1 row(s)
hive> SELECT  id, name FROM employee;
OK
1       Ian
2       Beatrice
3       Vladimir
4       Whitney
5       Leslie
6       Bernard
7       Mary
8       Jerome
9       Joshua
10      Keane
11      Velma
12      Rogan
13      Aurelia
14      Merrill
15      Blaine
Time taken: 0.191 seconds, Fetched: 15 row(s)
hive> SELECT * FROM employee WHERE salary > 30000;
OK
2       Beatrice        Tech Support    2021    35330
3       Vladimir        Human Resources 2020    51445
5       Leslie  Customer Service        2021    59882
6       Bernard IT      2021    50330
8       Jerome  RnD     2021    45333
9       Joshua  IT      2021    59538
10      Keane   Human Resources 2022    46500
14      Merrill Quality Assurance       2021    59660
Time taken: 0.318 seconds, Fetched: 8 row(s)
hive> SELECT count(*) FROM employee;
Query ID = root_20221228042944_8fcf3fd9-8d97-44fe-93b8-8730ef2e6176
Total jobs = 1
Launching Job 1 out of 1
Number of reduce tasks determined at compile time: 1
In order to change the average load for a reducer (in bytes):
  set hive.exec.reducers.bytes.per.reducer=<number>
In order to limit the maximum number of reducers:
  set hive.exec.reducers.max=<number>
In order to set a constant number of reducers:
  set mapreduce.job.reduces=<number>
Starting Job = job_1672201518957_0002, Tracking URL = http://039eda7161c0:8088/proxy/application_1672201518957_0002/
Kill Command = /usr/local/hadoop/bin/mapred job  -kill job_1672201518957_0002
Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1
2022-12-28 04:29:56,501 Stage-1 map = 0%,  reduce = 0%
2022-12-28 04:30:01,780 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 3.26 sec
2022-12-28 04:30:09,137 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 6.88 sec
MapReduce Total cumulative CPU time: 6 seconds 880 msec
Ended Job = job_1672201518957_0002
MapReduce Jobs Launched:
Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 6.88 sec   HDFS Read: 13254 HDFS Write: 102 SUCCESS
Total MapReduce CPU Time Spent: 6 seconds 880 msec
OK
15
Time taken: 26.824 seconds, Fetched: 1 row(s)
hive> INSERT OVERWRITE [LOCAL] DIRECTORY directory
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
    >  SELECT * FROM emp.employee;
NoViableAltException(362@[])
        at org.apache.hadoop.hive.ql.parse.HiveParser.destination(HiveParser.java:41819)
        at org.apache.hadoop.hive.ql.parse.HiveParser.insertClause(HiveParser.java:41588)
        at org.apache.hadoop.hive.ql.parse.HiveParser.regularBody(HiveParser.java:39556)
        at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpressionBody(HiveParser.java:38900)
        at org.apache.hadoop.hive.ql.parse.HiveParser.queryStatementExpression(HiveParser.java:38788)
        at org.apache.hadoop.hive.ql.parse.HiveParser.execStatement(HiveParser.java:2396)
        at org.apache.hadoop.hive.ql.parse.HiveParser.statement(HiveParser.java:1420)
        at org.apache.hadoop.hive.ql.parse.ParseDriver.parse(ParseDriver.java:220)
        at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:74)
        at org.apache.hadoop.hive.ql.parse.ParseUtils.parse(ParseUtils.java:67)
        at org.apache.hadoop.hive.ql.Driver.compile(Driver.java:616)
        at org.apache.hadoop.hive.ql.Driver.compileInternal(Driver.java:1826)
        at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1773)
        at org.apache.hadoop.hive.ql.Driver.compileAndRespond(Driver.java:1768)
        at org.apache.hadoop.hive.ql.reexec.ReExecDriver.compileAndRespond(ReExecDriver.java:126)
        at org.apache.hadoop.hive.ql.reexec.ReExecDriver.run(ReExecDriver.java:214)
        at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:239)
        at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:188)
        at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:402)
        at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:821)
        at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:759)
        at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:683)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:498)
        at org.apache.hadoop.util.RunJar.run(RunJar.java:323)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:236)
FAILED: ParseException line 1:17 cannot recognize input near '[' 'LOCAL' ']' in destination specification
hive> INSERT OVERWRITE DIRECTORY '/user/root/output/export'
    > ROW FORMAT DELIMITED FIELDS TERMINATED BY ','
    > SELECT * FROM emp.employee;
FAILED: SemanticException [Error 10001]: Line 3:14 Table not found 'employee'
hive>
